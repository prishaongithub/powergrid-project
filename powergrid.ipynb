{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "951b8991-d204-41b3-8230-a2a3c4cca140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'clf__C': 0.1, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        79\n",
      "           1       0.74      1.00      0.85       221\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.37      0.50      0.42       300\n",
      "weighted avg       0.54      0.74      0.62       300\n",
      "\n",
      "Accuracy: 0.7366666666666667\n",
      "Precision: 0.7366666666666667\n",
      "Recall: 1.0\n",
      "ROC-AUC: 0.5988315481986368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files written:\n",
      " - C:\\Users\\Prisha\\Desktop\\POWERGRID\\towers_metadata.csv\n",
      " - C:\\Users\\Prisha\\Desktop\\POWERGRID\\tower_daily.csv\n",
      " - C:\\Users\\Prisha\\Desktop\\POWERGRID\\graph_edges.csv\n",
      " - C:\\Users\\Prisha\\Desktop\\POWERGRID\\tower_data.csv\n",
      " - C:\\Users\\Prisha\\Desktop\\POWERGRID\\fault_prediction_model.pkl\n",
      " - C:\\Users\\Prisha\\Desktop\\POWERGRID\\model_features.pkl\n",
      " - C:\\Users\\Prisha\\Desktop\\POWERGRID\\roc_curve.png\n",
      " - C:\\Users\\Prisha\\Desktop\\POWERGRID\\confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate enhanced dataset + train & export model.\n",
    "\n",
    "Outputs:\n",
    "- towers_metadata.csv         (static per tower: region, age, corrosion, coords, distance, last_maintenance)\n",
    "- tower_daily.csv             (per-tower-per-day dynamic sensor values + labels)\n",
    "- graph_edges.csv             (sparse undirected road graph incl. substation edges)\n",
    "- tower_data.csv              (merged training-ready table, for convenience)\n",
    "- fault_prediction_model.pkl  (scikit-learn pipeline)\n",
    "- model_features.pkl          (ordered feature list for inference alignment)\n",
    "- roc_curve.png, confusion_matrix.png (saved plots)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import combinations\n",
    "import os\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, roc_auc_score, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# -------------------\n",
    "# Reproducibility\n",
    "# -------------------\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# -------------------\n",
    "# Parameters\n",
    "# -------------------\n",
    "n_towers = 25\n",
    "n_days = 60                 # ~2 months\n",
    "start_date = datetime(2024, 5, 1)\n",
    "regions = [\"North\", \"South\", \"East\", \"West\"]\n",
    "\n",
    "# Coordinate space and substation\n",
    "GRID_MIN, GRID_MAX = 0, 100\n",
    "SUB_ID = \"SUB\"\n",
    "SUB_X, SUB_Y = 50, 50\n",
    "\n",
    "# Road graph sparsity\n",
    "K_NEIGHBORS = 4          # each tower connects to its 4 nearest towers\n",
    "K_SUB_EDGES = 6          # substation connects to its 6 nearest towers\n",
    "\n",
    "# -------------------\n",
    "# Helper functions\n",
    "# -------------------\n",
    "def euclidean(x1, y1, x2, y2):\n",
    "    return float(np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# -------------------\n",
    "# Generate static tower metadata (one row per tower)\n",
    "# -------------------\n",
    "towers = [f\"T{i+1}\" for i in range(n_towers)]\n",
    "meta_rows = []\n",
    "\n",
    "for t in towers:\n",
    "    tower_age = np.random.randint(5, 40)\n",
    "    corrosion = np.random.randint(0, 100)\n",
    "    region = random.choice(regions)\n",
    "    region_risk = np.random.randint(1, 10)\n",
    "    last_maintenance = datetime(2024, 1, 1) + timedelta(days=np.random.randint(0, 365))\n",
    "\n",
    "    # coordinates\n",
    "    x = np.random.randint(GRID_MIN, GRID_MAX + 1)\n",
    "    y = np.random.randint(GRID_MIN, GRID_MAX + 1)\n",
    "    dist_sub = euclidean(x, y, SUB_X, SUB_Y)\n",
    "\n",
    "    meta_rows.append({\n",
    "        \"tower_id\": t,\n",
    "        \"region\": region,\n",
    "        \"region_risk_score\": region_risk,\n",
    "        \"tower_age_years\": tower_age,\n",
    "        \"corrosion_level\": corrosion,\n",
    "        \"last_maintenance\": last_maintenance.date(),\n",
    "        \"x\": x,\n",
    "        \"y\": y,\n",
    "        \"distance_from_substation\": dist_sub\n",
    "    })\n",
    "\n",
    "df_meta = pd.DataFrame(meta_rows)\n",
    "df_meta.to_csv(\"towers_metadata.csv\", index=False)\n",
    "\n",
    "# -------------------\n",
    "# Build a sparse undirected road graph (edges)\n",
    "# -------------------\n",
    "# compute pairwise distances\n",
    "coords = df_meta.set_index(\"tower_id\")[[\"x\", \"y\"]].to_dict(\"index\")\n",
    "\n",
    "# K-nearest neighbors per tower\n",
    "edges = set()\n",
    "for t in towers:\n",
    "    x1, y1 = coords[t][\"x\"], coords[t][\"y\"]\n",
    "    dists = []\n",
    "    for u in towers:\n",
    "        if u == t: \n",
    "            continue\n",
    "        x2, y2 = coords[u][\"x\"], coords[u][\"y\"]\n",
    "        d = euclidean(x1, y1, x2, y2)\n",
    "        dists.append((u, d))\n",
    "    dists.sort(key=lambda z: z[1])\n",
    "    for u, d in dists[:K_NEIGHBORS]:\n",
    "        edge = tuple(sorted([t, u]))\n",
    "        edges.add((edge[0], edge[1], d))\n",
    "\n",
    "# connect substation to K nearest towers\n",
    "df_meta_sorted = df_meta.sort_values(\"distance_from_substation\")\n",
    "for _, row in df_meta_sorted.head(K_SUB_EDGES).iterrows():\n",
    "    d = row[\"distance_from_substation\"]\n",
    "    edges.add((SUB_ID, row[\"tower_id\"], d))\n",
    "\n",
    "df_edges = pd.DataFrame(list(edges), columns=[\"source\", \"target\", \"distance\"])\n",
    "df_edges.to_csv(\"graph_edges.csv\", index=False)\n",
    "\n",
    "# -------------------\n",
    "# Generate daily dynamic data and labels\n",
    "# -------------------\n",
    "daily_rows = []\n",
    "for t in towers:\n",
    "    meta = df_meta[df_meta[\"tower_id\"] == t].iloc[0]\n",
    "    tower_age = meta[\"tower_age_years\"]\n",
    "    corrosion = meta[\"corrosion_level\"]\n",
    "    region_risk = meta[\"region_risk_score\"]\n",
    "    last_maint = pd.to_datetime(meta[\"last_maintenance\"])\n",
    "\n",
    "    for day in range(n_days):\n",
    "        date = start_date + timedelta(days=day)\n",
    "        # dynamic sensors\n",
    "        rain = np.random.randint(0, 100)\n",
    "        wind = np.random.randint(0, 120)\n",
    "        temp = np.random.randint(-5, 45)\n",
    "        freq = np.random.uniform(49, 51)\n",
    "        volt = np.random.uniform(200, 240)\n",
    "        overload = np.random.randint(50, 150)\n",
    "\n",
    "        # anomalies\n",
    "        freq_anom = 1 if (freq < 49.5 or freq > 50.5) else 0\n",
    "        volt_anom = 1 if (volt < 210 or volt > 230) else 0\n",
    "        anomaly_chances = freq_anom + volt_anom\n",
    "\n",
    "        # days since maintenance (semi-dynamic)\n",
    "        days_since_maintenance = (date - last_maint).days\n",
    "\n",
    "        # underlying risk score (same logic you used + small noise)\n",
    "        score = (\n",
    "            0.4 * anomaly_chances +\n",
    "            0.3 * (corrosion / 100) +\n",
    "            0.2 * (tower_age / 40) +\n",
    "            0.3 * (rain / 100) +\n",
    "            0.2 * (wind / 120) +\n",
    "            0.1 * (region_risk / 10) +\n",
    "            np.random.normal(0, 0.05)\n",
    "        )\n",
    "        prob_fault = sigmoid(score)\n",
    "        faulty = np.random.rand() < prob_fault\n",
    "\n",
    "        daily_rows.append({\n",
    "            \"tower_id\": t,\n",
    "            \"date\": date.date(),\n",
    "            \"rain_intensity\": rain,\n",
    "            \"wind_speed\": wind,\n",
    "            \"temperature\": temp,\n",
    "            \"frequency\": freq,\n",
    "            \"voltage\": volt,\n",
    "            \"overload_current_pct\": overload,\n",
    "            \"freq_anomaly\": freq_anom,\n",
    "            \"volt_anomaly\": volt_anom,\n",
    "            \"anomaly_chances\": anomaly_chances,\n",
    "            \"days_since_maintenance\": days_since_maintenance,\n",
    "            \"faulty\": int(faulty)\n",
    "        })\n",
    "\n",
    "df_daily = pd.DataFrame(daily_rows)\n",
    "df_daily.to_csv(\"tower_daily.csv\", index=False)\n",
    "\n",
    "# -------------------\n",
    "# Merge training table (static + dynamic)\n",
    "# -------------------\n",
    "df_train = df_daily.merge(df_meta, on=\"tower_id\", how=\"left\")\n",
    "\n",
    "# For convenience, also save a single training csv like before\n",
    "df_train.to_csv(\"tower_data.csv\", index=False)\n",
    "\n",
    "# -------------------\n",
    "# Train / Evaluate / Export model (Logistic Regression pipeline)\n",
    "# -------------------\n",
    "# Features & target\n",
    "drop_cols = [\"date\", \"last_maintenance\", \"faulty\", \"tower_id\"]\n",
    "X = df_train.drop(columns=drop_cols)\n",
    "# one-hot region\n",
    "X = pd.get_dummies(X, columns=[\"region\"], drop_first=True)\n",
    "y = df_train[\"faulty\"]\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__C\": [0.1, 1, 10,100],\n",
    "    \"clf__penalty\": [\"l1\", \"l2\"],\n",
    "    \"clf__solver\": [\"liblinear\", \"saga\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline, param_grid, cv=5, scoring=\"f1\", n_jobs=-1, verbose=0\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# predictions & metrics\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "# plots saved to disk\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_curve.png\", dpi=160)\n",
    "plt.close()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure()\n",
    "plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, [\"No Fault\", \"Fault\"])\n",
    "plt.yticks(tick_marks, [\"No Fault\", \"Fault\"])\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=160)\n",
    "plt.close()\n",
    "\n",
    "# Export model + feature order (critical for inference)\n",
    "joblib.dump(best_model, \"fault_prediction_model.pkl\")\n",
    "joblib.dump(list(X.columns), \"model_features.pkl\")\n",
    "\n",
    "print(\"\\nFiles written:\")\n",
    "for f in [\n",
    "    \"towers_metadata.csv\", \"tower_daily.csv\", \"graph_edges.csv\",\n",
    "    \"tower_data.csv\", \"fault_prediction_model.pkl\", \"model_features.pkl\",\n",
    "    \"roc_curve.png\", \"confusion_matrix.png\"\n",
    "]:\n",
    "    print(\" -\", os.path.abspath(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd2724-d6ce-44ee-8b4c-313136cb20ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
